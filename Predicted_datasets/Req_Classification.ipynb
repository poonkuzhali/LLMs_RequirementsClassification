{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be5a3e1f370d6572",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T00:30:19.095956Z",
     "start_time": "2024-11-04T00:30:18.094723Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4e1e6c952a106b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T00:30:19.103201Z",
     "start_time": "2024-11-04T00:30:19.097729Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"medical_req_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "743bfc52eb437958",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T01:37:48.049171Z",
     "start_time": "2024-11-04T01:37:48.036926Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_openai_client():\n",
    "    with open(\"../openai_api_key.txt\", \"r\") as file:\n",
    "        openai_api_key = file.read().strip()\n",
    "        return OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d21df376d9f13e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T00:30:19.108562Z",
     "start_time": "2024-11-04T00:30:19.105638Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_label(model, client, text):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Classify the following requirement as either 'FR' (Functional \"\n",
    "                                                  f\"Requirement) or 'NFR' (Non-Functional Requirement): {text}\"}]\n",
    "        )\n",
    "        label = response.choices[0].message.content.strip()\n",
    "        return label\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating label for text: {text}\\n{e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21cd694752eb18f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T00:30:19.114043Z",
     "start_time": "2024-11-04T00:30:19.109936Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_labeled_dataset(model):\n",
    "    client = get_openai_client()\n",
    "    model_id = model.split(\"::\")[1]\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        text = row[\"Requirement Text\"]\n",
    "        gen_label = generate_label(model, client, text)\n",
    "        df.at[index, \"Generated_Label\"] = gen_label\n",
    "\n",
    "    df.to_csv(f\"{model_id}_labeled_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e928d9eecf221df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T00:38:24.168254Z",
     "start_time": "2024-11-04T00:38:24.160070Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def metrics(model):\n",
    "    df = pd.read_csv(f\"{model}_labeled_dataset.csv\")\n",
    "    true_labels = df['Label']\n",
    "    generated_labels = df['Generated_Label']\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, generated_labels)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, generated_labels, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, generated_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2015a57fd24ccf71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T00:45:07.160474Z",
     "start_time": "2024-11-04T00:38:30.053359Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95625\n",
      "Precision: 0.9569125234521575\n",
      "Recall: 0.95625\n",
      "F1 Score: 0.9562448728465955\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          FR       0.94      0.97      0.96       158\n",
      "         NFR       0.97      0.94      0.96       162\n",
      "\n",
      "    accuracy                           0.96       320\n",
      "   macro avg       0.96      0.96      0.96       320\n",
      "weighted avg       0.96      0.96      0.96       320\n",
      "Accuracy: 0.765625\n",
      "Precision: 0.8098115560949299\n",
      "Recall: 0.765625\n",
      "F1 Score: 0.7590278478458279\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          FR       0.69      0.95      0.80       158\n",
      "         NFR       0.92      0.59      0.72       162\n",
      "  proposalFR       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.77       320\n",
      "   macro avg       0.54      0.51      0.51       320\n",
      "weighted avg       0.81      0.77      0.76       320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/poonkuzhali.saran/PycharmProjects/GRE2/myvenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/poonkuzhali.saran/PycharmProjects/GRE2/myvenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/poonkuzhali.saran/PycharmProjects/GRE2/myvenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/poonkuzhali.saran/PycharmProjects/GRE2/myvenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "model1 = \"ft:gpt-4o-mini-2024-07-18:personal::APIxXqIF\" #PURE\n",
    "model2 = \"ft:gpt-4o-mini-2024-07-18:personal::APdkJsuS\" #PROMISE\n",
    "\n",
    "generate_labeled_dataset(model1)\n",
    "model_id = model1.split(\"::\")[1]\n",
    "metrics(model_id)\n",
    "\n",
    "\n",
    "generate_labeled_dataset(model2)\n",
    "model_id = model2.split(\"::\")[1]\n",
    "metrics(model_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
